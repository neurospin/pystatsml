{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction and feature extraction\n",
    "\n",
    "## Principal Component Analysis\n",
    "\n",
    "### Implement PCA\n",
    "\n",
    "- Write a class `BasicPCA` with two methods `fit(X)` that estimates the data mean and principal components directions. `transform(X)` that project a new the data into the principal components.\n",
    "\n",
    "- Check that your `BasicPCA` performed similarly to the one from sklearn:\n",
    "`from sklearn.decomposition import PCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "class BasicPCA():\n",
    "    def fit(self, X):\n",
    "        # U : Unitary matrix having left singular vectors as columns.\n",
    "        #     Of shape (n_samples,n_samples) or (n_samples,n_comps), depending on\n",
    "        #     full_matrices.\n",
    "        #\n",
    "        # s : The singular values, sorted in non-increasing order. Of shape (n_comps,), \n",
    "        #     with n_comps = min(n_samples, n_features).\n",
    "        #\n",
    "        # Vh: Unitary matrix having right singular vectors as rows. \n",
    "        #     Of shape (n_features, n_features) or (n_comps, n_features) depending on full_matrices.\n",
    "        self.mean = X.mean(axis=0)\n",
    "        Xc = X - self.mean  # Centering is required\n",
    "        U, s, V = scipy.linalg.svd(Xc, full_matrices=False)\n",
    "        self.explained_variance_ = (s ** 2) / X.shape[0]\n",
    "        self.explained_variance_ratio_ = (self.explained_variance_ /\n",
    "                                 self.explained_variance_.sum())\n",
    "        self.princ_comp_dir = V\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xc = X - self.mean\n",
    "        return(np.dot(Xc, self.princ_comp_dir.T))\n",
    "\n",
    "# test\n",
    "np.random.seed(42)\n",
    " \n",
    "# dataset\n",
    "n_samples = 100\n",
    "experience = np.random.normal(size=n_samples)\n",
    "salary = 1500 + experience + np.random.normal(size=n_samples, scale=.5)\n",
    "X = np.column_stack([experience, salary])\n",
    "\n",
    "X = np.column_stack([experience, salary])\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "\n",
    "basic_pca = BasicPCA()\n",
    "basic_pca.fit(X)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "assert np.all(basic_pca.transform(X) == pca.transform(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA on iris dataset\n",
    "\n",
    "Apply your sklearn PCA on `iris` dataset available at: 'https://raw.github.com/neurospin/pystatsml/master/datasets/iris.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# https://tgmstat.wordpress.com/2013/11/28/computing-and-visualizing-pca-in-r/\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    salary = pd.read_csv('datasets/iris.csv')\n",
    "except:\n",
    "    url = 'https://raw.github.com/neurospin/pystatsml/master/datasets/iris.csv'\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the data set. Should the dataset been standardized ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the structure of correlation among variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:, :4])\n",
    "#np.around(np.corrcoef(X.T), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center and standardize\n",
    "\n",
    "X = np.array(df.iloc[:, :4])\n",
    "X -= np.mean(X, axis=0)\n",
    "X /= np.std(X, axis=0, ddof=1)\n",
    "np.around(np.corrcoef(X.T), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a PCA with the maximum number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=X.shape[1])\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the explained variance ratio. Determine $K$ the number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "K = 2\n",
    "pca = PCA(n_components=X.shape[1])\n",
    "pca.fit(X)\n",
    "PC = pca.transform(X)\n",
    "#print(PC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the $K$ principal components direction and correlation of the $K$ principal\n",
    "components with original variables. Interpret the contribution of original variables\n",
    "into the PC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)\n",
    "CorPC = pd.DataFrame(\n",
    "    [[np.corrcoef(X[:, j], PC[:, k])[0, 1] for j in range(X.shape[1])]\n",
    "        for k in range(K)],\n",
    "            columns = df.columns[:4],\n",
    "    index = [\"PC %i\"%k for k in range(K)]\n",
    ")\n",
    "\n",
    "print(CorPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot samples projected into the $K$ first PCs. Color samples with their species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'setosa':'r', 'versicolor':'g', 'virginica':'blue'}\n",
    "print(df[\"species\"].unique())\n",
    "#plt.scatter(df['experience'], df['salary'], c=df['education'].apply(lambda x: colors[x]), s=100)\n",
    "plt.scatter(PC[:, 0], PC[:, 1], c=df[\"species\"].apply(lambda x: colors[x]))\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairewise plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df[\"PC1\"] = PC[:, 0]\n",
    "df[\"PC2\"] = PC[:, 1]\n",
    "\n",
    "sns.pairplot(df, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "%matplotlib inline\n",
    "\n",
    "# https://tgmstat.wordpress.com/2013/11/28/computing-and-visualizing-pca-in-r/\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    salary = pd.read_csv('datasets/iris.csv')\n",
    "except:\n",
    "    url = 'https://raw.githubusercontent.com/neurospin/pystatsml/master/datasets/iris.csv'\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "X = np.asarray(df.iloc[:, :4])\n",
    "X -= np.mean(X, axis=0)\n",
    "X /= np.std(X, axis=0, ddof=1)\n",
    "\n",
    "from sklearn import metrics\n",
    "D = metrics.pairwise.pairwise_distances(X, metric='euclidean')\n",
    "\n",
    "\n",
    "stress = [MDS(dissimilarity='precomputed', n_components=k,\n",
    "           random_state=42, max_iter=300, eps=1e-9).fit(D).stress_ for k in range(1, X.shape[1]+1)]\n",
    "\n",
    "print(\"Stress\", stress)\n",
    "plt.plot(range(1, 5), stress)\n",
    "\n",
    "K = 2\n",
    "mds = MDS(dissimilarity='precomputed', n_components=K,\n",
    "           random_state=42, max_iter=300, eps=1e-9)\n",
    "Xmds = mds.fit_transform(D)\n",
    "\n",
    "pca = PCA(n_components=K)\n",
    "pca.fit(X)\n",
    "PC = pca.transform(X)\n",
    "\n",
    "print(\"Correlation between PCA and MDS\")\n",
    "cor = [np.corrcoef(Xmds[:, j], PC[:, j])[0, 1] for j in range(min(Xmds.shape[1], PC.shape[1]))]\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
